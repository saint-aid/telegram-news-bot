import requests
from bs4 import BeautifulSoup

headers = {
    "User-Agent": "Mozilla/5.0"
}

def get_headlines(limit=3, category_sid1="101", keywords=None):
    url = f"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1={category_sid1}"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    links = soup.select("a[href*='/article/']")

    articles = []
    seen = set()

    # print(f"[DEBUG] category_sid1={category_sid1}, keywords={keywords}")
    # print(f"[DEBUG] Found {len(links)} raw links on page")
    # print(f"[DEBUG] Collected {len(articles)} articles after filtering")

    for link_tag in links:
        title = link_tag.get_text(strip=True)
        link = link_tag["href"]

        if link in seen or not title or not link:
            continue
        seen.add(link)

        content = get_article_content(link)

        # ğŸ¯ í‚¤ì›Œë“œ í•„í„°ë§
        if keywords and not any(k in content for k in keywords):
            continue

        if len(content.split()) < 30:
            continue

        articles.append({
            "title": title,
            "link": link,
            "content": content
        })

        if len(articles) >= limit:
            break

    return articles


def get_article_content(url):
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        # ë‰´ìŠ¤ ë³¸ë¬¸ íŒŒì‹±
        article_tag = soup.select_one("article")
        if article_tag:
            return article_tag.get_text(separator=" ", strip=True)

        # ë§Œì•½ <article> íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì˜ˆì™¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
        div_tag = soup.select_one("div#newsct_article")  # ëª¨ë°”ì¼ ë„¤ì´ë²„ ë‰´ìŠ¤
        if div_tag:
            return div_tag.get_text(separator=" ", strip=True)

        return "[ë³¸ë¬¸ ì—†ìŒ]"
    except Exception as e:
        return f"[ë³¸ë¬¸ ë¡œë”© ì‹¤íŒ¨: {e}]"
